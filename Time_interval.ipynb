{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db40ad38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "available-albany",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import os\n",
    "import importlib\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "pd.set_option('mode.chained_assignment',  None) \n",
    "\n",
    "\n",
    "module_path='preprocessing/day_intervals_preproc'\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "module_path='utils'\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "    \n",
    "module_path='preprocessing/hosp_module_preproc'\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "    \n",
    "module_path='model'\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "#print(sys.path)\n",
    "root_dir = os.path.dirname(os.path.abspath('UserInterface.ipynb'))\n",
    "import day_intervals_cohort\n",
    "from day_intervals_cohort import *\n",
    "\n",
    "import day_intervals_cohort_v2\n",
    "from day_intervals_cohort_v2 import *\n",
    "\n",
    "import data_generation_icu\n",
    "\n",
    "import data_generation\n",
    "\n",
    "import feature_selection_hosp\n",
    "from feature_selection_hosp import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "nutritional-chicago",
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(day_intervals_cohort)\n",
    "import day_intervals_cohort\n",
    "from day_intervals_cohort import *\n",
    "\n",
    "importlib.reload(day_intervals_cohort_v2)\n",
    "import day_intervals_cohort_v2\n",
    "from day_intervals_cohort_v2 import *\n",
    "\n",
    "importlib.reload(data_generation_icu)\n",
    "import data_generation_icu\n",
    "importlib.reload(data_generation)\n",
    "import data_generation\n",
    "# importlib.reload(data_generation_circ)\n",
    "import data_generation_circ\n",
    "\n",
    "# importlib.reload(feature_selection_hosp)\n",
    "import feature_selection_hosp\n",
    "from feature_selection_hosp import *\n",
    "\n",
    "# importlib.reload(feature_selection_icu)\n",
    "import feature_selection_icu\n",
    "from feature_selection_icu import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fleet-canyon",
   "metadata": {},
   "outputs": [],
   "source": [
    "if data_icu:\n",
    "    # gen=data_generation_circ.Generator(cohort_output,data_mort,data_admn,data_los,diag_flag,proc_flag,out_flag,chart_flag,med_flag,ing_flag,lab_flag,impute,include,bucket, predW)\n",
    "    gen=data_generation_circ.Generator(cohort_output,data_mort,data_admn,data_los,True,True,True,True,True,True,True,impute,include,bucket, predW)\n",
    "    #gen=data_generation_icu.Generator(cohort_output,data_mort,diag_flag,False,False,chart_flag,False,impute,include,bucket,predW)\n",
    "    #if chart_flag:\n",
    "    #    gen=data_generation_icu.Generator(cohort_output,data_mort,False,False,False,chart_flag,False,impute,include,bucket,predW)\n",
    "else:\n",
    "    gen=data_generation.Generator(cohort_output,data_mort,data_admn,data_los,diag_flag,lab_flag,proc_flag,med_flag,impute,include,bucket,predW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7f588a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_adm():\n",
    "    data=pd.read_csv(f\"./data/cohort/cohort_icu_mortality_0_.csv.gz\", compression='gzip', header=0, index_col=None)\n",
    "    data['intime'] = pd.to_datetime(data['intime'])\n",
    "    data['outtime'] = pd.to_datetime(data['outtime'])\n",
    "    data['los']=pd.to_timedelta(data['outtime']-data['intime'],unit='h')\n",
    "    data['los']=data['los'].astype(str)\n",
    "    data[['days', 'dummy','hours']] = data['los'].str.split(' ', -1, expand=True)\n",
    "    data[['hours','min','sec']] = data['hours'].str.split(':', -1, expand=True)\n",
    "    data['los']=pd.to_numeric(data['days'])*24+pd.to_numeric(data['hours'])\n",
    "    data=data.drop(columns=['days', 'dummy','hours','min','sec'])\n",
    "    data=data[data['los']>0]\n",
    "    data['Age']=data['Age'].astype(int)\n",
    "    #print(data.head())\n",
    "    #print(data.shape)\n",
    "    return data\n",
    "\n",
    "data = generate_adm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2b455385",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>stay_id</th>\n",
       "      <th>intime</th>\n",
       "      <th>outtime</th>\n",
       "      <th>Age</th>\n",
       "      <th>gender</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>insurance</th>\n",
       "      <th>label</th>\n",
       "      <th>dod</th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>los</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000032</td>\n",
       "      <td>39553978</td>\n",
       "      <td>2180-07-23 14:00:00</td>\n",
       "      <td>2180-07-23 23:50:47</td>\n",
       "      <td>52</td>\n",
       "      <td>F</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>Medicaid</td>\n",
       "      <td>0</td>\n",
       "      <td>2180-09-09 00:00:00</td>\n",
       "      <td>29079034</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10000980</td>\n",
       "      <td>39765666</td>\n",
       "      <td>2189-06-27 08:42:00</td>\n",
       "      <td>2189-06-27 20:38:27</td>\n",
       "      <td>73</td>\n",
       "      <td>F</td>\n",
       "      <td>BLACK/AFRICAN AMERICAN</td>\n",
       "      <td>Medicare</td>\n",
       "      <td>0</td>\n",
       "      <td>2193-08-26 00:00:00</td>\n",
       "      <td>26913865</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10001217</td>\n",
       "      <td>37067082</td>\n",
       "      <td>2157-11-20 19:18:02</td>\n",
       "      <td>2157-11-21 22:08:00</td>\n",
       "      <td>55</td>\n",
       "      <td>F</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>Other</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24597018</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10001217</td>\n",
       "      <td>34592300</td>\n",
       "      <td>2157-12-19 15:42:24</td>\n",
       "      <td>2157-12-20 14:27:41</td>\n",
       "      <td>55</td>\n",
       "      <td>F</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>Other</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27703517</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10001725</td>\n",
       "      <td>31205490</td>\n",
       "      <td>2110-04-11 15:52:22</td>\n",
       "      <td>2110-04-12 23:59:56</td>\n",
       "      <td>46</td>\n",
       "      <td>F</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>Other</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25563031</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73176</th>\n",
       "      <td>19999442</td>\n",
       "      <td>32336619</td>\n",
       "      <td>2148-11-19 14:23:43</td>\n",
       "      <td>2148-11-26 13:12:15</td>\n",
       "      <td>41</td>\n",
       "      <td>M</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>Medicaid</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26785317</td>\n",
       "      <td>166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73177</th>\n",
       "      <td>19999625</td>\n",
       "      <td>31070865</td>\n",
       "      <td>2139-10-10 19:18:00</td>\n",
       "      <td>2139-10-11 18:21:28</td>\n",
       "      <td>81</td>\n",
       "      <td>M</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>Medicare</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25304202</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73178</th>\n",
       "      <td>19999828</td>\n",
       "      <td>36075953</td>\n",
       "      <td>2149-01-08 18:12:00</td>\n",
       "      <td>2149-01-10 13:11:02</td>\n",
       "      <td>46</td>\n",
       "      <td>F</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>Other</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25744818</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73179</th>\n",
       "      <td>19999840</td>\n",
       "      <td>38978960</td>\n",
       "      <td>2164-09-12 09:26:28</td>\n",
       "      <td>2164-09-17 16:35:15</td>\n",
       "      <td>58</td>\n",
       "      <td>M</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>Other</td>\n",
       "      <td>1</td>\n",
       "      <td>2164-09-17 00:00:00</td>\n",
       "      <td>21033226</td>\n",
       "      <td>127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73180</th>\n",
       "      <td>19999987</td>\n",
       "      <td>36195440</td>\n",
       "      <td>2145-11-02 22:59:00</td>\n",
       "      <td>2145-11-04 21:29:30</td>\n",
       "      <td>57</td>\n",
       "      <td>F</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>Other</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23865745</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>73073 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       subject_id   stay_id              intime             outtime  Age  \\\n",
       "0        10000032  39553978 2180-07-23 14:00:00 2180-07-23 23:50:47   52   \n",
       "1        10000980  39765666 2189-06-27 08:42:00 2189-06-27 20:38:27   73   \n",
       "2        10001217  37067082 2157-11-20 19:18:02 2157-11-21 22:08:00   55   \n",
       "3        10001217  34592300 2157-12-19 15:42:24 2157-12-20 14:27:41   55   \n",
       "4        10001725  31205490 2110-04-11 15:52:22 2110-04-12 23:59:56   46   \n",
       "...           ...       ...                 ...                 ...  ...   \n",
       "73176    19999442  32336619 2148-11-19 14:23:43 2148-11-26 13:12:15   41   \n",
       "73177    19999625  31070865 2139-10-10 19:18:00 2139-10-11 18:21:28   81   \n",
       "73178    19999828  36075953 2149-01-08 18:12:00 2149-01-10 13:11:02   46   \n",
       "73179    19999840  38978960 2164-09-12 09:26:28 2164-09-17 16:35:15   58   \n",
       "73180    19999987  36195440 2145-11-02 22:59:00 2145-11-04 21:29:30   57   \n",
       "\n",
       "      gender               ethnicity insurance  label                  dod  \\\n",
       "0          F                   WHITE  Medicaid      0  2180-09-09 00:00:00   \n",
       "1          F  BLACK/AFRICAN AMERICAN  Medicare      0  2193-08-26 00:00:00   \n",
       "2          F                   WHITE     Other      0                    0   \n",
       "3          F                   WHITE     Other      0                    0   \n",
       "4          F                   WHITE     Other      0                    0   \n",
       "...      ...                     ...       ...    ...                  ...   \n",
       "73176      M                   WHITE  Medicaid      0                    0   \n",
       "73177      M                   WHITE  Medicare      0                    0   \n",
       "73178      F                   WHITE     Other      0                    0   \n",
       "73179      M                   WHITE     Other      1  2164-09-17 00:00:00   \n",
       "73180      F                 UNKNOWN     Other      0                    0   \n",
       "\n",
       "        hadm_id  los  \n",
       "0      29079034    9  \n",
       "1      26913865   11  \n",
       "2      24597018   26  \n",
       "3      27703517   22  \n",
       "4      25563031   32  \n",
       "...         ...  ...  \n",
       "73176  26785317  166  \n",
       "73177  25304202   23  \n",
       "73178  25744818   42  \n",
       "73179  21033226  127  \n",
       "73180  23865745   46  \n",
       "\n",
       "[73073 rows x 12 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1d469445",
   "metadata": {},
   "outputs": [],
   "source": [
    "     \n",
    "# def generate_cond():\n",
    "#         cond=pd.read_csv(\"./data/features/preproc_diag_icu.csv.gz\", compression='gzip', header=0, index_col=None)\n",
    "#         cond=cond[cond['stay_id'].isin(data['stay_id'])]\n",
    "#         cond_per_adm = cond.groupby('stay_id').size().max()\n",
    "#         return cond, cond_per_adm\n",
    "    \n",
    "def generate_proc():\n",
    "    proc=pd.read_csv(\"./data/features/preproc_proc_icu.csv.gz\", compression='gzip', header=0, index_col=None)\n",
    "    proc=proc[proc['stay_id'].isin(data['stay_id'])]\n",
    "    proc[['start_days', 'dummy','start_hours']] = proc['event_time_from_admit'].str.split(' ', -1, expand=True)\n",
    "    proc[['start_hours','min','sec']] = proc['start_hours'].str.split(':', -1, expand=True)\n",
    "    proc['start_time']=pd.to_numeric(proc['start_days'])*24+pd.to_numeric(proc['start_hours'])\n",
    "    proc=proc.drop(columns=['start_days', 'dummy','start_hours','min','sec'])\n",
    "    proc=proc[proc['start_time']>=0]\n",
    "    \n",
    "    ###Remove where event time is after discharge time\n",
    "    proc=pd.merge(proc,data[['stay_id','los']],on='stay_id',how='left')\n",
    "    proc['sanity']=proc['los']-proc['start_time']\n",
    "    proc=proc[proc['sanity']>0]\n",
    "    del proc['sanity']\n",
    "    \n",
    "    return proc\n",
    "    \n",
    "def generate_out():\n",
    "    out=pd.read_csv(\"./data/features/preproc_out_icu.csv.gz\", compression='gzip', header=0, index_col=None)\n",
    "    out=out[out['stay_id'].isin(data['stay_id'])]\n",
    "    out[['start_days', 'dummy','start_hours']] = out['event_time_from_admit'].str.split(' ', -1, expand=True)\n",
    "    out[['start_hours','min','sec']] = out['start_hours'].str.split(':', -1, expand=True)\n",
    "    out['start_time']=pd.to_numeric(out['start_days'])*24+pd.to_numeric(out['start_hours'])\n",
    "    out=out.drop(columns=['start_days', 'dummy','start_hours','min','sec'])\n",
    "    out=out[out['start_time']>=0]\n",
    "    \n",
    "    ###Remove where event time is after discharge time\n",
    "    out=pd.merge(out,data[['stay_id','los']],on='stay_id',how='left')\n",
    "    out['sanity']=out['los']-out['start_time']\n",
    "    out=out[out['sanity']>0]\n",
    "    del out['sanity']\n",
    "    \n",
    "    return out\n",
    "    \n",
    "    \n",
    "def generate_chart():\n",
    "    chunksize = 5000000\n",
    "    final=pd.DataFrame()\n",
    "    for chart in tqdm(pd.read_csv(\"./data/features/preproc_chart_icu.csv.gz\", compression='gzip', header=0, index_col=None,chunksize=chunksize)):\n",
    "        chart=chart[chart['stay_id'].isin(data['stay_id'])]\n",
    "        chart[['start_days', 'dummy','start_hours']] = chart['event_time_from_admit'].str.split(' ', -1, expand=True)\n",
    "        chart[['start_hours','min','sec']] = chart['start_hours'].str.split(':', -1, expand=True)\n",
    "        chart['start_time']=pd.to_numeric(chart['start_days'])*24+pd.to_numeric(chart['start_hours'])\n",
    "        chart=chart.drop(columns=['start_days', 'dummy','start_hours','min','sec','event_time_from_admit'])\n",
    "        chart=chart[chart['start_time']>=0]\n",
    "\n",
    "        ###Remove where event time is after discharge time\n",
    "        chart=pd.merge(chart,data[['stay_id','los']],on='stay_id',how='left')\n",
    "        chart['sanity']=chart['los']-chart['start_time']\n",
    "        chart=chart[chart['sanity']>0]\n",
    "        del chart['sanity']\n",
    "        del chart['los']\n",
    "        \n",
    "        if final.empty:\n",
    "            final=chart\n",
    "        else:\n",
    "            final=final.append(chart, ignore_index=True)\n",
    "    \n",
    "    return final\n",
    "    \n",
    "\n",
    "def generate_labs():\n",
    "    chunksize = 10000000\n",
    "    final=pd.DataFrame()\n",
    "    for labs in tqdm(pd.read_csv(\"./data/features/preproc_labs.csv.gz\", compression='gzip', header=0, index_col=None,chunksize=chunksize)):\n",
    "        labs=labs[labs['hadm_id'].isin(data['hadm_id'])]\n",
    "        labs[['start_days', 'dummy','start_hours']] = labs['lab_time_from_admit'].str.split(' ', -1, expand=True)\n",
    "        labs[['start_hours','min','sec']] = labs['start_hours'].str.split(':', -1, expand=True)\n",
    "        labs['start_time']=pd.to_numeric(labs['start_days'])*24+pd.to_numeric(labs['start_hours'])\n",
    "        labs=labs.drop(columns=['start_days', 'dummy','start_hours','min','sec'])\n",
    "        labs=labs[labs['start_time']>=0]\n",
    "\n",
    "        ###Remove where event time is after discharge time\n",
    "        labs=pd.merge(labs,data[['hadm_id','los']],on='hadm_id',how='left')\n",
    "        labs['sanity']=labs['los']-labs['start_time']\n",
    "        labs=labs[labs['sanity']>0]\n",
    "        del labs['sanity']\n",
    "        \n",
    "        if final.empty:\n",
    "            final=labs\n",
    "        else:\n",
    "            final=final.append(labs, ignore_index=True)\n",
    "\n",
    "    return final\n",
    "    \n",
    "    \n",
    "def generate_meds():\n",
    "    meds=pd.read_csv(\"./data/features/preproc_med_icu.csv.gz\", compression='gzip', header=0, index_col=None)\n",
    "    meds[['start_days', 'dummy','start_hours']] = meds['start_hours_from_admit'].str.split(' ', -1, expand=True)\n",
    "    meds[['start_hours','min','sec']] = meds['start_hours'].str.split(':', -1, expand=True)\n",
    "    meds['start_time']=pd.to_numeric(meds['start_days'])*24+pd.to_numeric(meds['start_hours'])\n",
    "    meds[['start_days', 'dummy','start_hours']] = meds['stop_hours_from_admit'].str.split(' ', -1, expand=True)\n",
    "    meds[['start_hours','min','sec']] = meds['start_hours'].str.split(':', -1, expand=True)\n",
    "    meds['stop_time']=pd.to_numeric(meds['start_days'])*24+pd.to_numeric(meds['start_hours'])\n",
    "    meds=meds.drop(columns=['start_days', 'dummy','start_hours','min','sec'])\n",
    "    #####Sanity check\n",
    "    meds['sanity']=meds['stop_time']-meds['start_time']\n",
    "    meds=meds[meds['sanity']>0]\n",
    "    del meds['sanity']\n",
    "    #####Select hadm_id as in main file\n",
    "    meds=meds[meds['stay_id'].isin(data['stay_id'])]\n",
    "    meds=pd.merge(meds,data[['stay_id','los']],on='stay_id',how='left')\n",
    "\n",
    "    #####Remove where start time is after end of visit\n",
    "    meds['sanity']=meds['los']-meds['start_time']\n",
    "    meds=meds[meds['sanity']>0]\n",
    "    del meds['sanity']\n",
    "    ####Any stop_time after end of visit is set at end of visit\n",
    "    meds.loc[meds['stop_time'] > meds['los'],'stop_time']=meds.loc[meds['stop_time'] > meds['los'],'los']\n",
    "    del meds['los']\n",
    "    \n",
    "    meds['rate']=meds['rate'].apply(pd.to_numeric, errors='coerce')\n",
    "    meds['amount']=meds['amount'].apply(pd.to_numeric, errors='coerce')\n",
    "    \n",
    "    return meds\n",
    "    \n",
    "def generate_ing():\n",
    "    ing=pd.read_csv(\"./data/features/preproc_ing_icu.csv.gz\", compression='gzip', header=0, index_col=None)\n",
    "    ing[['start_days', 'dummy','start_hours']] = ing['start_hours_from_admit'].str.split(' ', -1, expand=True)\n",
    "    ing[['start_hours','min','sec']] = ing['start_hours'].str.split(':', -1, expand=True)\n",
    "    ing['start_time']=pd.to_numeric(ing['start_days'])*24+pd.to_numeric(ing['start_hours'])\n",
    "    ing[['start_days', 'dummy','start_hours']] = ing['stop_hours_from_admit'].str.split(' ', -1, expand=True)\n",
    "    ing[['start_hours','min','sec']] = ing['start_hours'].str.split(':', -1, expand=True)\n",
    "    ing['stop_time']=pd.to_numeric(ing['start_days'])*24+pd.to_numeric(ing['start_hours'])\n",
    "    ing=ing.drop(columns=['start_days', 'dummy','start_hours','min','sec'])\n",
    "    #####Sanity check\n",
    "    ing['sanity']=ing['stop_time']-ing['start_time']\n",
    "    ing=ing[ing['sanity']>0]\n",
    "    del ing['sanity']\n",
    "    #####Select hadm_id as in main file\n",
    "    ing=ing[ing['stay_id'].isin(data['stay_id'])]\n",
    "    ing=pd.merge(ing,data[['stay_id','los']],on='stay_id',how='left')\n",
    "\n",
    "    #####Remove where start time is after end of visit\n",
    "    ing['sanity']=ing['los']-ing['start_time']\n",
    "    ing=ing[ing['sanity']>0]\n",
    "    del ing['sanity']\n",
    "    ####Any stop_time after end of visit is set at end of visit\n",
    "    ing.loc[ing['stop_time'] > ing['los'],'stop_time']=ing.loc[ing['stop_time'] > ing['los'],'los']\n",
    "    del ing['los']\n",
    "    \n",
    "    ing['rate']=ing['rate'].apply(pd.to_numeric, errors='coerce')\n",
    "    ing['amount']=ing['amount'].apply(pd.to_numeric, errors='coerce')\n",
    "    \n",
    "    return ing\n",
    "\n",
    "\n",
    "def get_stay_id(labs, chart):\n",
    "            \n",
    "    stay = pd.read_csv(\"./\"+\"mimiciv/2.2\"+\"/icu/icustays.csv.gz\")\n",
    "    stay = stay[stay.notna()]\n",
    "    \n",
    "    chart['charttime'] = pd.to_datetime(chart['charttime'])\n",
    "    labs['charttime'] = pd.to_datetime(labs['charttime'])\n",
    "\n",
    "    stay['intime'] = pd.to_datetime(stay['intime'])\n",
    "    stay['outtime'] = pd.to_datetime(stay['outtime'])\n",
    "\n",
    "\n",
    "    labs['stay_id'] = np.nan\n",
    "    result = []\n",
    "\n",
    "    unique_patient_ids = labs['subject_id'].unique()\n",
    "\n",
    "    for p in tqdm(range(len(unique_patient_ids))):\n",
    "        \n",
    "        p_id = unique_patient_ids[p]\n",
    "        \n",
    "        lab = labs[labs['subject_id']==p_id].copy().sort_values('charttime').reset_index(drop=True)\n",
    "        stay_interest = stay[stay['subject_id']==p_id].copy()\n",
    "        \n",
    "        unique_stay_ids = stay_interest['stay_id'].unique()\n",
    "        \n",
    "        for s in  tqdm(range(len(unique_stay_ids)), leave=False):\n",
    "            \n",
    "            stay_id = unique_stay_ids[s]\n",
    "            \n",
    "            stay_interest2 = stay_interest[stay_interest['stay_id']==stay_id].copy()\n",
    "            \n",
    "            indices = np.where((lab['charttime'].values >= stay_interest2['intime'].values) & \n",
    "                            (lab['charttime'].values <= stay_interest2['outtime'].values))\n",
    "\n",
    "            lab['stay_id'].loc[indices[0]] = stay_id\n",
    "\n",
    "            result.append(lab)\n",
    "            \n",
    "    result_df = pd.concat(result)\n",
    "    labs = result_df[~(result_df['stay_id'].isnull())]\n",
    "    return labs\n",
    "    \n",
    "    \n",
    "# ing = generate_ing()\n",
    "\n",
    "# chart = generate_chart()\n",
    "\n",
    "# labs = generate_labs()\n",
    "\n",
    "# labs = get_stay_id(labs, chart)\n",
    "\n",
    "# cond, cond_per_adm = generate_cond()\n",
    "\n",
    "proc = generate_proc()\n",
    "\n",
    "out = generate_out()\n",
    "\n",
    "meds = generate_meds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ad5d3b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('check_point_data.csv')\n",
    "ing.to_csv('check_point_ing.csv')\n",
    "chart.to_csv('check_point_chart.csv')\n",
    "labs.to_csv('check_point_labs.csv')\n",
    "# cond.to_csv('check_point_cond.csv')\n",
    "proc.to_csv('check_point_proc.csv')\n",
    "out.to_csv('check_point_out.csv')\n",
    "meds.to_csv('check_point_meds.csv')\n",
    "# cond_per_adm.to_csv('check_point_cond_per_adm.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "578167bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "data = pd.read_csv('check_point_data.csv', index_col = 0)\n",
    "ing = pd.read_csv('check_point_ing.csv', index_col = 0)\n",
    "chart = pd.read_csv('check_point_chart.csv', index_col = 0)\n",
    "labs = pd.read_csv('check_point_labs.csv', index_col = 0)\n",
    "proc = pd.read_csv('check_point_proc.csv', index_col = 0)\n",
    "out = pd.read_csv('check_point_out.csv', index_col = 0)\n",
    "meds = pd.read_csv('check_point_meds.csv', index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4988fd68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "include start time 48\n",
      "include end time 360\n",
      "num of patient:  25881\n",
      "num of stay:  32811\n"
     ]
    }
   ],
   "source": [
    "include_start_time = 2*24\n",
    "include_end_time = 15*24\n",
    "\n",
    "def mortality_length(include_start_time,include_end_time,data, meds, ing, proc, out, chart, labs):\n",
    "    print(\"include start time\",include_start_time)\n",
    "    print(\"include end time\",include_end_time)\n",
    "    \n",
    "    data=data[(data['los'] >= include_start_time)]\n",
    "    data=data[(data['los'] <= include_end_time)]\n",
    "    hids=data['stay_id'].unique()\n",
    "    print('num of patient: ', len(data.subject_id.unique()))\n",
    "    print('num of stay: ', len(hids))\n",
    "\n",
    "    # cond=cond[cond['stay_id'].isin(data['stay_id'])]\n",
    "    \n",
    "    ###MEDS\n",
    "\n",
    "    meds=meds[meds['stay_id'].isin(data['stay_id'])]\n",
    "    meds=meds[meds['start_time'] <= include_end_time]\n",
    "    meds.loc[meds.stop_time > include_end_time, 'stop_time']=include_end_time\n",
    "        \n",
    "    ###ING\n",
    "\n",
    "    ing=ing[ing['stay_id'].isin(data['stay_id'])]\n",
    "    ing=ing[ing['start_time'] <= include_end_time]\n",
    "    ing.loc[ing.stop_time > include_end_time, 'stop_time']=include_end_time\n",
    "                \n",
    "    \n",
    "    ###PROCS\n",
    "\n",
    "    proc=proc[proc['stay_id'].isin(data['stay_id'])]\n",
    "    proc=proc[proc['start_time']<=include_end_time]\n",
    "        \n",
    "    ###OUT\n",
    "\n",
    "    out=out[out['stay_id'].isin(data['stay_id'])]\n",
    "    out=out[out['start_time']<=include_end_time]\n",
    "        \n",
    "    ###CHART\n",
    "\n",
    "    chart=chart[chart['stay_id'].isin(data['stay_id'])]\n",
    "    chart=chart[chart['start_time']<=include_end_time]\n",
    "        \n",
    "    ###LAB\n",
    "\n",
    "    labs=labs[labs['stay_id'].isin(data['stay_id'])]\n",
    "    labs=labs[labs['start_time']<=include_end_time]\n",
    "    \n",
    "    return  data, meds, ing, proc, out, chart, labs\n",
    "\n",
    "data, meds, ing, proc, out, chart, labs = mortality_length(include_start_time,include_end_time ,data, meds, ing, proc, out, chart, labs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca379386",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_meds=pd.DataFrame()\n",
    "final_ing=pd.DataFrame()\n",
    "final_proc=pd.DataFrame()\n",
    "final_out=pd.DataFrame()\n",
    "final_chart=pd.DataFrame()\n",
    "final_labs=pd.DataFrame()\n",
    "\n",
    "\n",
    "meds=meds.sort_values(by=['start_time'])\n",
    "ing=ing.sort_values(by=['start_time'])\n",
    "proc=proc.sort_values(by=['start_time'])\n",
    "out=out.sort_values(by=['start_time'])\n",
    "chart=chart.sort_values(by=['start_time'])\n",
    "labs=labs.sort_values(by=['start_time'])\n",
    "\n",
    "hids=data['stay_id'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c1fb700f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data = pd.concat([chart[['stay_id', 'itemid']], labs[['stay_id', 'itemid']]], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef5c8ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the item_ids we are interested in\n",
    "required_item_ids = {225668, 50813, 220045, 220739, 223900, 223901, 223835, 220224}\n",
    "\n",
    "# Find the stay_ids that have all the required item_ids at least once\n",
    "valid_stay_ids = sample_data[sample_data['itemid'].isin(required_item_ids)].groupby('stay_id')['itemid'].nunique()\n",
    "valid_stay_ids = valid_stay_ids[valid_stay_ids == len(required_item_ids)].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "25ef7606",
   "metadata": {},
   "outputs": [],
   "source": [
    "meds = meds[meds['stay_id'].isin(valid_stay_ids)]\n",
    "ing = ing[ing['stay_id'].isin(valid_stay_ids)]\n",
    "proc = proc[proc['stay_id'].isin(valid_stay_ids)]\n",
    "out = out[out['stay_id'].isin(valid_stay_ids)]\n",
    "chart = chart[chart['stay_id'].isin(valid_stay_ids)]\n",
    "labs = labs[labs['stay_id'].isin(valid_stay_ids)]\n",
    "data = data[data['stay_id'].isin(valid_stay_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "11717746",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(meds.itemid.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c019f335",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14073\n"
     ]
    }
   ],
   "source": [
    "print(len(data.subject_id.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f64a14a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15884\n"
     ]
    }
   ],
   "source": [
    "print(len(data.stay_id.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2120499"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['los'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "085cf6ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total stay with Processing:   0%|          | 7/15884 [00:09<5:42:56,  1.30s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\DAHS\\Desktop\\MIMIC_pipeline\\Time_interval.ipynb Cell 19\u001b[0m line \u001b[0;36m4\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/DAHS/Desktop/MIMIC_pipeline/Time_interval.ipynb#X21sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m sub_ing\u001b[39m=\u001b[39msub_ing\u001b[39m.\u001b[39mreset_index()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/DAHS/Desktop/MIMIC_pipeline/Time_interval.ipynb#X21sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m sub_ing[\u001b[39m'\u001b[39m\u001b[39mstart_time\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m=\u001b[39mt\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/DAHS/Desktop/MIMIC_pipeline/Time_interval.ipynb#X21sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m sub_ing[\u001b[39m'\u001b[39;49m\u001b[39mstop_time\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m=\u001b[39msub_ing[\u001b[39m'\u001b[39m\u001b[39mstop_time\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m/\u001b[39mbucket\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/DAHS/Desktop/MIMIC_pipeline/Time_interval.ipynb#X21sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m \u001b[39mif\u001b[39;00m final_ing\u001b[39m.\u001b[39mempty:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/DAHS/Desktop/MIMIC_pipeline/Time_interval.ipynb#X21sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m     final_ing\u001b[39m=\u001b[39msub_ing\n",
      "File \u001b[1;32mc:\\Users\\DAHS\\anaconda3\\envs\\MIMIC\\lib\\site-packages\\pandas\\core\\frame.py:3980\u001b[0m, in \u001b[0;36mDataFrame.__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   3977\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_setitem_array([key], value)\n\u001b[0;32m   3978\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   3979\u001b[0m     \u001b[39m# set column\u001b[39;00m\n\u001b[1;32m-> 3980\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_set_item(key, value)\n",
      "File \u001b[1;32mc:\\Users\\DAHS\\anaconda3\\envs\\MIMIC\\lib\\site-packages\\pandas\\core\\frame.py:4187\u001b[0m, in \u001b[0;36mDataFrame._set_item\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   4184\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(existing_piece, DataFrame):\n\u001b[0;32m   4185\u001b[0m             value \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mtile(value, (\u001b[39mlen\u001b[39m(existing_piece\u001b[39m.\u001b[39mcolumns), \u001b[39m1\u001b[39m))\u001b[39m.\u001b[39mT\n\u001b[1;32m-> 4187\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_set_item_mgr(key, value)\n",
      "File \u001b[1;32mc:\\Users\\DAHS\\anaconda3\\envs\\MIMIC\\lib\\site-packages\\pandas\\core\\frame.py:4146\u001b[0m, in \u001b[0;36mDataFrame._set_item_mgr\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   4144\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_mgr\u001b[39m.\u001b[39minsert(\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_info_axis), key, value)\n\u001b[0;32m   4145\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 4146\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_iset_item_mgr(loc, value)\n\u001b[0;32m   4148\u001b[0m \u001b[39m# check if we are modifying a copy\u001b[39;00m\n\u001b[0;32m   4149\u001b[0m \u001b[39m# try to set first as we want an invalid\u001b[39;00m\n\u001b[0;32m   4150\u001b[0m \u001b[39m# value exception to occur first\u001b[39;00m\n\u001b[0;32m   4151\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\DAHS\\anaconda3\\envs\\MIMIC\\lib\\site-packages\\pandas\\core\\frame.py:4136\u001b[0m, in \u001b[0;36mDataFrame._iset_item_mgr\u001b[1;34m(self, loc, value, inplace)\u001b[0m\n\u001b[0;32m   4132\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_iset_item_mgr\u001b[39m(\n\u001b[0;32m   4133\u001b[0m     \u001b[39mself\u001b[39m, loc: \u001b[39mint\u001b[39m \u001b[39m|\u001b[39m \u001b[39mslice\u001b[39m \u001b[39m|\u001b[39m np\u001b[39m.\u001b[39mndarray, value, inplace: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m   4134\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   4135\u001b[0m     \u001b[39m# when called from _set_item_mgr loc can be anything returned from get_loc\u001b[39;00m\n\u001b[1;32m-> 4136\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_mgr\u001b[39m.\u001b[39;49miset(loc, value, inplace\u001b[39m=\u001b[39;49minplace)\n\u001b[0;32m   4137\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_clear_item_cache()\n",
      "File \u001b[1;32mc:\\Users\\DAHS\\anaconda3\\envs\\MIMIC\\lib\\site-packages\\pandas\\core\\internals\\managers.py:1245\u001b[0m, in \u001b[0;36mBlockManager.iset\u001b[1;34m(self, loc, value, inplace)\u001b[0m\n\u001b[0;32m   1243\u001b[0m \u001b[39m# Accessing public blknos ensures the public versions are initialized\u001b[39;00m\n\u001b[0;32m   1244\u001b[0m blknos \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mblknos[loc]\n\u001b[1;32m-> 1245\u001b[0m blklocs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mblklocs[loc]\u001b[39m.\u001b[39;49mcopy()\n\u001b[0;32m   1247\u001b[0m unfit_mgr_locs \u001b[39m=\u001b[39m []\n\u001b[0;32m   1248\u001b[0m unfit_val_locs \u001b[39m=\u001b[39m []\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "pd.set_option('mode.chained_assignment',  None) \n",
    "\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "bucket = 1\n",
    "\n",
    "\n",
    "for hid in tqdm(valid_stay_ids, desc = f'Total stay with Processing'):\n",
    "    grp = data[data['stay_id']==hid]\n",
    "    los = int(grp['los'].values[0])\n",
    "\n",
    "    new_meds = meds[meds['stay_id']==hid]\n",
    "    new_ing = ing[ing['stay_id']==hid]\n",
    "    new_proc = proc[proc['stay_id']==hid]\n",
    "    new_out = out[out['stay_id']==hid]\n",
    "    new_chart = chart[chart['stay_id']==hid]\n",
    "    new_labs = labs[labs['stay_id']==hid]\n",
    "    \n",
    "    t = 0\n",
    "    for i in np.arange(0,los,bucket): \n",
    "        ###MED\n",
    "        \n",
    "        sub_meds=new_meds[(new_meds['start_time']>=i) & (new_meds['start_time']<i+bucket)].groupby(['stay_id','itemid','orderid']).agg({'stop_time':'max','subject_id':'max','rate':np.nanmean,'amount':np.nanmean})\n",
    "        sub_meds=sub_meds.reset_index()\n",
    "        sub_meds['start_time']=t\n",
    "        sub_meds['stop_time']=sub_meds['stop_time']/bucket\n",
    "        if final_meds.empty:\n",
    "            final_meds=sub_meds\n",
    "        else:\n",
    "            final_meds=final_meds.append(sub_meds)\n",
    "\n",
    "        ###ING\n",
    "\n",
    "        sub_ing=new_ing[(new_ing['start_time']>=i) & (new_ing['start_time']<i+bucket)].groupby(['stay_id','itemid','orderid']).agg({'stop_time':'max','subject_id':'max','rate':np.nanmean,'amount':np.nanmean})\n",
    "        sub_ing=sub_ing.reset_index()\n",
    "        sub_ing['start_time']=t\n",
    "        sub_ing['stop_time']=sub_ing['stop_time']/bucket\n",
    "        if final_ing.empty:\n",
    "            final_ing=sub_ing\n",
    "        else:\n",
    "            final_ing=final_ing.append(sub_ing)\n",
    "            \n",
    "        ###PROC\n",
    "\n",
    "        sub_proc=new_proc[(new_proc['start_time']>=i) & (new_proc['start_time']<i+bucket)].groupby(['stay_id','itemid']).agg({'subject_id':'max'})\n",
    "        sub_proc=sub_proc.reset_index()\n",
    "        sub_proc['start_time']=t\n",
    "        if final_proc.empty:\n",
    "            final_proc=sub_proc\n",
    "        else:    \n",
    "            final_proc=final_proc.append(sub_proc)\n",
    "                \n",
    "        ###OUT\n",
    "\n",
    "        sub_out=new_out[(new_out['start_time']>=i) & (new_out['start_time']<i+bucket)].groupby(['stay_id','itemid']).agg({'value':np.nanmean})\n",
    "        sub_out=sub_out.reset_index()\n",
    "        sub_out['start_time']=t\n",
    "        if final_out.empty:\n",
    "            final_out=sub_out\n",
    "        else:    \n",
    "            final_out=final_out.append(sub_out)\n",
    "                    \n",
    "                    \n",
    "        ###CHART\n",
    "\n",
    "        sub_chart=new_chart[(new_chart['start_time']>=i) & (new_chart['start_time']<i+bucket)].groupby(['stay_id','itemid']).agg({'valuenum':np.nanmean})\n",
    "        sub_chart=sub_chart.reset_index()\n",
    "        sub_chart['start_time']=t\n",
    "        if final_chart.empty:\n",
    "            final_chart=sub_chart\n",
    "        else:    \n",
    "            final_chart=final_chart.append(sub_chart)\n",
    "                    \n",
    "        ###LAB\n",
    "\n",
    "        sub_labs=new_labs[(new_labs['start_time']>=i) & (new_labs['start_time']<i+bucket)].groupby(['stay_id','itemid']).agg({'valuenum':np.nanmean})\n",
    "        sub_labs=sub_labs.reset_index()\n",
    "        sub_labs['start_time']=t\n",
    "        if final_labs.empty:\n",
    "            final_labs=sub_labs\n",
    "        else:    \n",
    "            final_labs=final_labs.append(sub_labs)\n",
    "        \n",
    "        t=t+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d395f444",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_meds.to_csv('check_point_meds(resampled)(resampled).csv', compression = 'gzip')\n",
    "final_ing.to_csv('check_point_ing(resampled).csv', compression = 'gzip')\n",
    "final_proc.to_csv('check_point_proc(resampled).csv', compression = 'gzip')\n",
    "final_out.to_csv('check_point_out(resampled).csv', compression = 'gzip')\n",
    "final_chart.to_csv('check_point_chart(resampled).csv', compression = 'gzip')\n",
    "final_labs.to_csv('check_point_lab(resampled).csv', compression = 'gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "622752da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tabularize EHR for total stay 15,884:  43%|████▎     | 6807/15884 [01:25<01:54, 79.20it/s] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\DAHS\\Desktop\\MIMIC_pipeline\\Time_interval.ipynb Cell 20\u001b[0m line \u001b[0;36m2\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/DAHS/Desktop/MIMIC_pipeline/Time_interval.ipynb#X22sZmlsZQ%3D%3D?line=293'>294</a>\u001b[0m         dyn_csv\u001b[39m=\u001b[39mpd\u001b[39m.\u001b[39mconcat([dyn_csv,val],axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/DAHS/Desktop/MIMIC_pipeline/Time_interval.ipynb#X22sZmlsZQ%3D%3D?line=295'>296</a>\u001b[0m \u001b[39m#Save temporal data to csv\u001b[39;00m\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Users/DAHS/Desktop/MIMIC_pipeline/Time_interval.ipynb#X22sZmlsZQ%3D%3D?line=296'>297</a>\u001b[0m dyn_csv\u001b[39m.\u001b[39;49mto_csv(\u001b[39m'\u001b[39;49m\u001b[39m./data/csv/\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m+\u001b[39;49m\u001b[39mstr\u001b[39;49m(hid)\u001b[39m+\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m/dynamic.csv\u001b[39;49m\u001b[39m'\u001b[39;49m,index\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n",
      "File \u001b[1;32mc:\\Users\\DAHS\\anaconda3\\envs\\MIMIC\\lib\\site-packages\\pandas\\util\\_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[39m=\u001b[39m new_arg_value\n\u001b[1;32m--> 211\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\DAHS\\anaconda3\\envs\\MIMIC\\lib\\site-packages\\pandas\\core\\generic.py:3720\u001b[0m, in \u001b[0;36mNDFrame.to_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[0;32m   3709\u001b[0m df \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m, ABCDataFrame) \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mto_frame()\n\u001b[0;32m   3711\u001b[0m formatter \u001b[39m=\u001b[39m DataFrameFormatter(\n\u001b[0;32m   3712\u001b[0m     frame\u001b[39m=\u001b[39mdf,\n\u001b[0;32m   3713\u001b[0m     header\u001b[39m=\u001b[39mheader,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3717\u001b[0m     decimal\u001b[39m=\u001b[39mdecimal,\n\u001b[0;32m   3718\u001b[0m )\n\u001b[1;32m-> 3720\u001b[0m \u001b[39mreturn\u001b[39;00m DataFrameRenderer(formatter)\u001b[39m.\u001b[39;49mto_csv(\n\u001b[0;32m   3721\u001b[0m     path_or_buf,\n\u001b[0;32m   3722\u001b[0m     lineterminator\u001b[39m=\u001b[39;49mlineterminator,\n\u001b[0;32m   3723\u001b[0m     sep\u001b[39m=\u001b[39;49msep,\n\u001b[0;32m   3724\u001b[0m     encoding\u001b[39m=\u001b[39;49mencoding,\n\u001b[0;32m   3725\u001b[0m     errors\u001b[39m=\u001b[39;49merrors,\n\u001b[0;32m   3726\u001b[0m     compression\u001b[39m=\u001b[39;49mcompression,\n\u001b[0;32m   3727\u001b[0m     quoting\u001b[39m=\u001b[39;49mquoting,\n\u001b[0;32m   3728\u001b[0m     columns\u001b[39m=\u001b[39;49mcolumns,\n\u001b[0;32m   3729\u001b[0m     index_label\u001b[39m=\u001b[39;49mindex_label,\n\u001b[0;32m   3730\u001b[0m     mode\u001b[39m=\u001b[39;49mmode,\n\u001b[0;32m   3731\u001b[0m     chunksize\u001b[39m=\u001b[39;49mchunksize,\n\u001b[0;32m   3732\u001b[0m     quotechar\u001b[39m=\u001b[39;49mquotechar,\n\u001b[0;32m   3733\u001b[0m     date_format\u001b[39m=\u001b[39;49mdate_format,\n\u001b[0;32m   3734\u001b[0m     doublequote\u001b[39m=\u001b[39;49mdoublequote,\n\u001b[0;32m   3735\u001b[0m     escapechar\u001b[39m=\u001b[39;49mescapechar,\n\u001b[0;32m   3736\u001b[0m     storage_options\u001b[39m=\u001b[39;49mstorage_options,\n\u001b[0;32m   3737\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\DAHS\\anaconda3\\envs\\MIMIC\\lib\\site-packages\\pandas\\util\\_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[39m=\u001b[39m new_arg_value\n\u001b[1;32m--> 211\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\DAHS\\anaconda3\\envs\\MIMIC\\lib\\site-packages\\pandas\\io\\formats\\format.py:1189\u001b[0m, in \u001b[0;36mDataFrameRenderer.to_csv\u001b[1;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[0;32m   1168\u001b[0m     created_buffer \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m   1170\u001b[0m csv_formatter \u001b[39m=\u001b[39m CSVFormatter(\n\u001b[0;32m   1171\u001b[0m     path_or_buf\u001b[39m=\u001b[39mpath_or_buf,\n\u001b[0;32m   1172\u001b[0m     lineterminator\u001b[39m=\u001b[39mlineterminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1187\u001b[0m     formatter\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfmt,\n\u001b[0;32m   1188\u001b[0m )\n\u001b[1;32m-> 1189\u001b[0m csv_formatter\u001b[39m.\u001b[39;49msave()\n\u001b[0;32m   1191\u001b[0m \u001b[39mif\u001b[39;00m created_buffer:\n\u001b[0;32m   1192\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(path_or_buf, StringIO)\n",
      "File \u001b[1;32mc:\\Users\\DAHS\\anaconda3\\envs\\MIMIC\\lib\\site-packages\\pandas\\io\\formats\\csvs.py:261\u001b[0m, in \u001b[0;36mCSVFormatter.save\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    241\u001b[0m \u001b[39mwith\u001b[39;00m get_handle(\n\u001b[0;32m    242\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfilepath_or_buffer,\n\u001b[0;32m    243\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmode,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    249\u001b[0m \n\u001b[0;32m    250\u001b[0m     \u001b[39m# Note: self.encoding is irrelevant here\u001b[39;00m\n\u001b[0;32m    251\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwriter \u001b[39m=\u001b[39m csvlib\u001b[39m.\u001b[39mwriter(\n\u001b[0;32m    252\u001b[0m         handles\u001b[39m.\u001b[39mhandle,\n\u001b[0;32m    253\u001b[0m         lineterminator\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlineterminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    258\u001b[0m         quotechar\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mquotechar,\n\u001b[0;32m    259\u001b[0m     )\n\u001b[1;32m--> 261\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_save()\n",
      "File \u001b[1;32mc:\\Users\\DAHS\\anaconda3\\envs\\MIMIC\\lib\\site-packages\\pandas\\io\\common.py:133\u001b[0m, in \u001b[0;36mIOHandles.__exit__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    132\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__exit__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 133\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclose()\n",
      "File \u001b[1;32mc:\\Users\\DAHS\\anaconda3\\envs\\MIMIC\\lib\\site-packages\\pandas\\io\\common.py:125\u001b[0m, in \u001b[0;36mIOHandles.close\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    123\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcreated_handles\u001b[39m.\u001b[39mremove(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle)\n\u001b[0;32m    124\u001b[0m \u001b[39mfor\u001b[39;00m handle \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcreated_handles:\n\u001b[1;32m--> 125\u001b[0m     handle\u001b[39m.\u001b[39;49mclose()\n\u001b[0;32m    126\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcreated_handles \u001b[39m=\u001b[39m []\n\u001b[0;32m    127\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mis_wrapped \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "feat_med = True\n",
    "feat_ing = True\n",
    "feat_proc = True\n",
    "feat_out = True\n",
    "feat_chart = True\n",
    "impute = True\n",
    "feat_lab = True\n",
    "\n",
    "for hid in tqdm(valid_stay_ids, desc = 'Tabularize EHR for total stay 15,884'):\n",
    "    grp=data[data['stay_id']==hid]\n",
    "    los = int(grp['los'].values)\n",
    "    \n",
    "    if not os.path.exists(\"./data/csv/\"+str(hid)):\n",
    "        os.makedirs(\"./data/csv/\"+str(hid))\n",
    "    \n",
    "    dyn_csv=pd.DataFrame()\n",
    "    \n",
    "    ###MEDS\n",
    "    if(feat_med):\n",
    "        feat=final_meds['itemid'].unique()\n",
    "        df2=final_meds[final_meds['stay_id']==hid]\n",
    "        if df2.shape[0]==0:\n",
    "            amount=pd.DataFrame(np.zeros([los,len(feat)]),columns=feat)\n",
    "            amount=amount.fillna(0)\n",
    "            amount.columns=pd.MultiIndex.from_product([[\"MEDS\"], amount.columns])\n",
    "        else:\n",
    "            rate=df2.pivot_table(index='start_time',columns='itemid',values='rate')\n",
    "            #print(rate)\n",
    "            amount=df2.pivot_table(index='start_time',columns='itemid',values='amount')\n",
    "            df2=df2.pivot_table(index='start_time',columns='itemid',values='stop_time')\n",
    "            #print(df2.shape)\n",
    "            add_indices = pd.Index(range(los)).difference(df2.index)\n",
    "            add_df = pd.DataFrame(index=add_indices, columns=df2.columns).fillna(np.nan)\n",
    "            df2=pd.concat([df2, add_df])\n",
    "            df2=df2.sort_index()\n",
    "            df2=df2.ffill()\n",
    "            df2=df2.fillna(0)\n",
    "\n",
    "            rate=pd.concat([rate, add_df])\n",
    "            rate=rate.sort_index()\n",
    "            rate=rate.ffill()\n",
    "            rate=rate.fillna(0)\n",
    "\n",
    "            amount=pd.concat([amount, add_df])\n",
    "            amount=amount.sort_index()\n",
    "            amount=amount.ffill()\n",
    "            amount=amount.fillna(0)\n",
    "            #print(df2.head())\n",
    "            df2.iloc[:,0:]=df2.iloc[:,0:].sub(df2.index,0)\n",
    "            df2[df2>0]=1\n",
    "            df2[df2<0]=0\n",
    "            rate.iloc[:,0:]=df2.iloc[:,0:]*rate.iloc[:,0:]\n",
    "            amount.iloc[:,0:]=df2.iloc[:,0:]*amount.iloc[:,0:]\n",
    "          \n",
    "            feat_df=pd.DataFrame(columns=list(set(feat)-set(amount.columns)))\n",
    "            feat_df_rate = pd.DataFrame(columns=list(set(feat)-set(rate.columns)))\n",
    "\n",
    "            amount=pd.concat([amount,feat_df],axis=1)\n",
    "            rate=pd.concat([rate,feat_df_rate],axis=1)\n",
    "\n",
    "            amount=amount[feat]\n",
    "            amount=amount.fillna(0)\n",
    "            rate=rate[feat]\n",
    "            rate=rate.fillna(0)\n",
    "#                 print(amount.columns)\n",
    "            amount.columns=pd.MultiIndex.from_product([[\"MEDS\"], amount.columns])\n",
    "            rate.columns=pd.MultiIndex.from_product([[\"MEDS Rate\"], rate.columns])\n",
    "\n",
    "            medication = pd.concat([amount, rate], axis = 1)\n",
    "            \n",
    "        if(dyn_csv.empty):\n",
    "            dyn_csv=medication\n",
    "        else:\n",
    "            dyn_csv=pd.concat([dyn_csv,medication],axis=1)\n",
    "        \n",
    "    \n",
    "    ###INGS\n",
    "    if(feat_ing):\n",
    "        feat=final_ing['itemid'].unique()\n",
    "        df2=final_ing[final_ing['stay_id']==hid]\n",
    "        if df2.shape[0]==0:\n",
    "            amount=pd.DataFrame(np.zeros([los,len(feat)]),columns=feat)\n",
    "            amount=amount.fillna(0)\n",
    "            amount.columns=pd.MultiIndex.from_product([[\"INGS\"], amount.columns])\n",
    "        else:\n",
    "            rate=df2.pivot_table(index='start_time',columns='itemid',values='rate')\n",
    "            #print(rate)\n",
    "            amount=df2.pivot_table(index='start_time',columns='itemid',values='amount')\n",
    "            df2=df2.pivot_table(index='start_time',columns='itemid',values='stop_time')\n",
    "            #print(df2.shape)\n",
    "            add_indices = pd.Index(range(los)).difference(df2.index)\n",
    "            add_df = pd.DataFrame(index=add_indices, columns=df2.columns).fillna(np.nan)\n",
    "            df2=pd.concat([df2, add_df])\n",
    "            df2=df2.sort_index()\n",
    "            df2=df2.ffill()\n",
    "            df2=df2.fillna(0)\n",
    "\n",
    "            rate=pd.concat([rate, add_df])\n",
    "            rate=rate.sort_index()\n",
    "            rate=rate.ffill()\n",
    "            rate=rate.fillna(0)\n",
    "\n",
    "            amount=pd.concat([amount, add_df])\n",
    "            amount=amount.sort_index()\n",
    "            amount=amount.ffill()\n",
    "            amount=amount.fillna(0)\n",
    "            \n",
    "            df2.iloc[:,0:]=df2.iloc[:,0:].sub(df2.index,0)\n",
    "            df2[df2>0]=1\n",
    "            df2[df2<0]=0\n",
    "            rate.iloc[:,0:]=df2.iloc[:,0:]*rate.iloc[:,0:]\n",
    "            amount.iloc[:,0:]=df2.iloc[:,0:]*amount.iloc[:,0:]\n",
    "\n",
    "            feat_df=pd.DataFrame(columns=list(set(feat)-set(amount.columns)))\n",
    "            feat_df_rate = pd.DataFrame(columns=list(set(feat)-set(rate.columns)))\n",
    "\n",
    "            amount=pd.concat([amount,feat_df],axis=1)\n",
    "            rate=pd.concat([rate,feat_df_rate],axis=1)\n",
    "\n",
    "            amount=amount[feat]\n",
    "            amount=amount.fillna(0)\n",
    "            rate=rate[feat]\n",
    "            rate=rate.fillna(0)\n",
    "            \n",
    "            amount.columns=pd.MultiIndex.from_product([[\"INGS\"], amount.columns])\n",
    "            rate.columns=pd.MultiIndex.from_product([[\"INGS Rate\"], rate.columns])\n",
    "\n",
    "            ingredients = pd.concat([amount, rate], axis = 1)\n",
    "            \n",
    "        if(dyn_csv.empty):\n",
    "            dyn_csv=medication\n",
    "        else:\n",
    "            dyn_csv=pd.concat([dyn_csv,medication],axis=1)\n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "    ###PROCS\n",
    "    if(feat_proc):\n",
    "        feat=final_proc['itemid'].unique()\n",
    "        df2=final_proc[final_proc['stay_id']==hid]\n",
    "        if df2.shape[0]==0:\n",
    "            df2=pd.DataFrame(np.zeros([los,len(feat)]),columns=feat)\n",
    "            df2=df2.fillna(0)\n",
    "            df2.columns=pd.MultiIndex.from_product([[\"PROC\"], df2.columns])\n",
    "        else:\n",
    "            df2['val']=1\n",
    "            #print(df2)\n",
    "            df2=df2.pivot_table(index='start_time',columns='itemid',values='val')\n",
    "            #print(df2.shape)\n",
    "            add_indices = pd.Index(range(los)).difference(df2.index)\n",
    "            add_df = pd.DataFrame(index=add_indices, columns=df2.columns).fillna(np.nan)\n",
    "            df2=pd.concat([df2, add_df])\n",
    "            df2=df2.sort_index()\n",
    "            df2=df2.fillna(0)\n",
    "            df2[df2>0]=1\n",
    "\n",
    "            feat_df=pd.DataFrame(columns=list(set(feat)-set(df2.columns)))\n",
    "            df2=pd.concat([df2,feat_df],axis=1)\n",
    "\n",
    "            df2=df2[feat]\n",
    "            df2=df2.fillna(0)\n",
    "            df2.columns=pd.MultiIndex.from_product([[\"PROC\"], df2.columns])\n",
    "        \n",
    "        if(dyn_csv.empty):\n",
    "            dyn_csv=df2\n",
    "        else:\n",
    "            dyn_csv=pd.concat([dyn_csv,df2],axis=1)\n",
    "        \n",
    "        \n",
    "    ###OUT\n",
    "    if(feat_out):\n",
    "        feat=final_out['itemid'].unique()\n",
    "        df2=final_out[final_out['stay_id']==hid]\n",
    "    \n",
    "        if df2.shape[0]==0:\n",
    "            val=pd.DataFrame(np.zeros([los,len(feat)]),columns=feat)\n",
    "            val=val.fillna(0)\n",
    "            val.columns=pd.MultiIndex.from_product([[\"OUT\"], val.columns])\n",
    "        else:\n",
    "            val=df2.pivot_table(index='start_time',columns='itemid',values='value')\n",
    "            df2['val']=1\n",
    "            df2=df2.pivot_table(index='start_time',columns='itemid',values='val')\n",
    "            #print(df2.shape)\n",
    "            add_indices = pd.Index(range(los)).difference(df2.index)\n",
    "            add_df = pd.DataFrame(index=add_indices, columns=df2.columns).fillna(np.nan)\n",
    "            df2=pd.concat([df2, add_df])\n",
    "            df2=df2.sort_index()\n",
    "            df2=df2.fillna(0)\n",
    "\n",
    "            val=pd.concat([val, add_df])\n",
    "            val=val.sort_index()\n",
    "            val=val.fillna(0)\n",
    "            \n",
    "            df2[df2>0]=1\n",
    "            df2[df2<0]=0\n",
    "\n",
    "            feat_df=pd.DataFrame(columns=list(set(feat)-set(val.columns)))\n",
    "            val=pd.concat([val,feat_df],axis=1)\n",
    "\n",
    "            val=val[feat]\n",
    "            val=val.fillna(0)\n",
    "            val.columns=pd.MultiIndex.from_product([[\"OUT\"], val.columns])\n",
    "        \n",
    "        if(dyn_csv.empty):\n",
    "            dyn_csv=val\n",
    "        else:\n",
    "            dyn_csv=pd.concat([dyn_csv,val],axis=1)\n",
    "            \n",
    "        \n",
    "    ###CHART\n",
    "    if(feat_chart):\n",
    "        feat=final_chart['itemid'].unique()\n",
    "        df2=final_chart[final_chart['stay_id']==hid]\n",
    "        if df2.shape[0]==0:\n",
    "            val=pd.DataFrame(np.zeros([los,len(feat)]),columns=feat)\n",
    "            val=val.fillna(0)\n",
    "            val.columns=pd.MultiIndex.from_product([[\"CHART\"], val.columns])\n",
    "        else:\n",
    "            val=df2.pivot_table(index='start_time',columns='itemid',values='valuenum')\n",
    "            df2['val']=1\n",
    "            df2=df2.pivot_table(index='start_time',columns='itemid',values='val')\n",
    "            #print(df2.shape)\n",
    "            add_indices = pd.Index(range(los)).difference(df2.index)\n",
    "            add_df = pd.DataFrame(index=add_indices, columns=df2.columns).fillna(np.nan)\n",
    "            df2=pd.concat([df2, add_df])\n",
    "            df2=df2.sort_index()\n",
    "            df2=df2.fillna(0)\n",
    "\n",
    "            val=pd.concat([val, add_df])\n",
    "            val=val.sort_index()\n",
    "            if impute:\n",
    "                val=val.ffill()\n",
    "                val=val.bfill()\n",
    "                val=val.interpolate()\n",
    "            val=val.fillna(0)\n",
    "\n",
    "            df2[df2>0]=1\n",
    "            df2[df2<0]=0\n",
    "\n",
    "            feat_df=pd.DataFrame(columns=list(set(feat)-set(val.columns)))\n",
    "            val=pd.concat([val,feat_df],axis=1)\n",
    "\n",
    "            val=val[feat]\n",
    "            val=val.fillna(0)\n",
    "            val.columns=pd.MultiIndex.from_product([[\"CHART\"], val.columns])\n",
    "        \n",
    "        if(dyn_csv.empty):\n",
    "            dyn_csv=val\n",
    "        else:\n",
    "            dyn_csv=pd.concat([dyn_csv,val],axis=1)\n",
    "    \n",
    "    ###LABS\n",
    "    if(feat_lab):\n",
    "        feat=final_labs['itemid'].unique()\n",
    "        df2=final_labs[final_labs['stay_id']==hid]\n",
    "        if df2.shape[0]==0:\n",
    "            val=pd.DataFrame(np.zeros([los,len(feat)]),columns=feat)\n",
    "            val=val.fillna(0)\n",
    "            val.columns=pd.MultiIndex.from_product([[\"LAB\"], val.columns])\n",
    "        else:\n",
    "            val=df2.pivot_table(index='start_time',columns='itemid',values='valuenum')\n",
    "            df2['val']=1\n",
    "            df2=df2.pivot_table(index='start_time',columns='itemid',values='val')\n",
    "            #print(df2.shape)\n",
    "            add_indices = pd.Index(range(los)).difference(df2.index)\n",
    "            add_df = pd.DataFrame(index=add_indices, columns=df2.columns).fillna(np.nan)\n",
    "            df2=pd.concat([df2, add_df])\n",
    "            df2=df2.sort_index()\n",
    "            df2=df2.fillna(0)\n",
    "\n",
    "            val=pd.concat([val, add_df])\n",
    "            val=val.sort_index()\n",
    "            if impute:\n",
    "                val=val.ffill()\n",
    "                val=val.bfill()\n",
    "                val=val.fillna(val.mean())\n",
    "            val=val.fillna(0)\n",
    "\n",
    "            df2[df2>0]=1\n",
    "            df2[df2<0]=0\n",
    "            \n",
    "            feat_df=pd.DataFrame(columns=list(set(feat)-set(val.columns)))\n",
    "            val=pd.concat([val,feat_df],axis=1)\n",
    "\n",
    "            val=val[feat]\n",
    "            val=val.fillna(0)\n",
    "            val.columns=pd.MultiIndex.from_product([[\"LAB\"], val.columns])\n",
    "        \n",
    "        if(dyn_csv.empty):\n",
    "            dyn_csv=val\n",
    "        else:\n",
    "            dyn_csv=pd.concat([dyn_csv,val],axis=1)\n",
    "    \n",
    "    #Save temporal data to csv\n",
    "    dyn_csv.to_csv('./data/csv/'+str(hid)+'/dynamic.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f941fc1b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
